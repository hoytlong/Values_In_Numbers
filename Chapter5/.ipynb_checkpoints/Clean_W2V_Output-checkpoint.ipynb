{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoyt\\Anaconda3\\lib\\site-packages\\gensim-2.0.0-py3.6-win-amd64.egg\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import gensim\n",
    "import argparse\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punc_cleaner(raw):\n",
    "    raw = re.sub(r'[一二三四五六七八九十]+[百千万]*', '', raw)   #replace all numbers\n",
    "    raw = re.sub(r'[×‥・○◎]+', '', raw)   #replace punctuation marks\n",
    "    raw = re.sub(r'[Ａ-Ｚ]+', '', raw)     #replace full-width letters\n",
    "    raw = re.sub(r'\\s+', ' ', raw)     #get rid of double spaces\n",
    "    return raw\n",
    "\n",
    "def name_cleaner(text, proper_names):\n",
    "    tokens = re.split(r'\\s', text)\n",
    "    targets = set(re.findall(r'[ァ-ヺ]+', raw)) #extract all katakana words\n",
    "    \n",
    "    #if it's in our proper name list then delete all instances\n",
    "    for target in targets:\n",
    "        if target in proper_names:\n",
    "            tokens = list(filter(lambda a: a != target, tokens))\n",
    "    \n",
    "    text = ' '.join(tokens)           #get rid of double spaces    \n",
    "    return text\n",
    "\n",
    "def periods(text):\n",
    "    #count periods\n",
    "    periods = re.findall(r'。', text)\n",
    "    \n",
    "    #tokenize text\n",
    "    text = re.split(r'\\s', text)\n",
    "    \n",
    "    return len(periods)/len(text)\n",
    "\n",
    "def get_proper_names():\n",
    "    proper_names = []\n",
    "    with open(\"./WordLists/ProperNames.txt\", 'r', encoding = \"utf-8\") as f:\n",
    "        for word in f.readlines():\n",
    "            proper_names.append(word.replace(\"\\n\", \"\"))\n",
    "    return proper_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path = './KindaiLemmaMerge'\n",
    "files = [file for file in os.listdir(corpus_path) if file.endswith('.txt')]\n",
    "\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14464, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'./Kindai_Meta.xlsx', sheetname='Sheet1')\n",
    "df = df[df['YEAR'] < 1960]\n",
    "df = df[df['YEAR'] > 1875]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pre-process texts and stick them in new folder\n",
    "input_path = './KindaiLemmaMerge'\n",
    "corpus_path = './KindaiW2VPreProcessed'\n",
    "input_files = [file for file in os.listdir(input_path) if file.endswith('.txt')]\n",
    "proper_names = get_proper_names()\n",
    "\n",
    "for i in range(len(input_files)):\n",
    "    file = input_files[i]\n",
    "    with open(os.path.join(input_path, file), 'r', encoding = 'utf-8') as f:\n",
    "        raw = f.read()\n",
    "        raw = punc_cleaner(raw)\n",
    "        raw = name_cleaner(raw, proper_names)  #strip proper names\n",
    "        with open(os.path.join(corpus_path, file), 'w', encoding=\"utf-8\") as g:\n",
    "            g.write(raw)\n",
    "        g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean the word2vec output to replace spaces with the word SPACE\n",
    "model_dir = './results_fic_bootstrap/word2vec_bootstrap'\n",
    "boot_files = [file for file in os.listdir(model_dir) if file.endswith('.txt')]\n",
    "\n",
    "for i in range(len(boot_files)):\n",
    "    file = boot_files[i]\n",
    "    with open(os.path.join(model_dir, file), 'r', encoding = 'utf-8') as f:\n",
    "        raw = f.read()\n",
    "        if re.findall(r'\\n -', raw):\n",
    "            raw = re.sub(r'\\n -', r'\\nSPACE -', raw)\n",
    "            with open(os.path.join(model_dir, file), 'w', encoding='utf-8') as g:\n",
    "                g.write(raw)\n",
    "            g.close()\n",
    "        elif re.findall(r'\\n 0', raw):\n",
    "            raw = re.sub(r'\\n 0', r'\\nSPACE 0', raw)\n",
    "            with open(os.path.join(model_dir, file), 'w', encoding='utf-8') as g:\n",
    "                g.write(raw)\n",
    "            g.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
